{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S9S8MZpPTIQd",
    "outputId": "2797f940-a357-465e-9e8a-b665be8fb80a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vk7s2smaTe0V",
    "outputId": "dc28886e-7f03-4d1b-a6fc-5a469779390a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QVPvdCHsTjtX",
    "outputId": "f55c83f8-9d9d-4665-a355-193749c50c0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\", num_labels=2)\n",
    "\n",
    "# Move the model to GPU (if available)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "B7agVyAXVnTe"
   },
   "outputs": [],
   "source": [
    "# Function to predict sentiment for a batch of dialogues (0 = Negative, 1 = Positive)\n",
    "def predict_sentiment_batch(dialogues):\n",
    "    # Tokenize the input text and move the tensors to the GPU\n",
    "    inputs = tokenizer(dialogues, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Run the model on the GPU\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_classes = torch.argmax(logits, dim=1).tolist()  # Get sentiment prediction for each sentence\n",
    "\n",
    "    return ['Positive' if x == 1 else 'Negative' for x in predicted_classes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1pEPT_HtTl4u",
    "outputId": "6ed2f9a7-a556-431e-f277-8096dd069254"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Cleaned_Dialogue  Happiness  Contentment  Confidence  Neutral  Sadness  \\\n",
      "0                 hey          1            0           0        0        0   \n",
      "1                  hi          1            0           0        0        0   \n",
      "2  pheebs whats wrong          0            0           0        0        1   \n",
      "3                  oh          0            0           0        0        0   \n",
      "4                 god          0            0           0        0        0   \n",
      "\n",
      "   Anger  Fear  Surprise  Disgust  Love  Excitement  Anticipation  Nostalgia  \\\n",
      "0      0     0         1        0     0           1             0          0   \n",
      "1      0     0         0        0     0           1             0          0   \n",
      "2      0     0         0        0     0           0             0          0   \n",
      "3      0     0         1        0     0           1             1          0   \n",
      "4      0     0         1        0     0           0             0          0   \n",
      "\n",
      "   Confusion  Frustration  Longing  Optimism Positive/Negative  \n",
      "0          0            0        0         0          Positive  \n",
      "1          0            0        0         1          Positive  \n",
      "2          0            0        0         0          Negative  \n",
      "3          0            0        0         0          Positive  \n",
      "4          0            0        0         0          Positive  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Friends dataset\n",
    "friends_df = pd.read_csv('/friends_dataset.csv')\n",
    "\n",
    "# Split the dataset into batches for faster processing\n",
    "batch_size = 8  # You can adjust this based on your system's memory\n",
    "chunks = [friends_df[i:i + batch_size] for i in range(0, len(friends_df), batch_size)]\n",
    "\n",
    "# Process each chunk and add predictions to the dataframe\n",
    "predictions = []\n",
    "for chunk in chunks:\n",
    "    dialogues = chunk['Cleaned_Dialogue'].tolist()\n",
    "    batch_predictions = predict_sentiment_batch(dialogues)\n",
    "    predictions.extend(batch_predictions)\n",
    "\n",
    "# Add the predictions to the dataframe\n",
    "friends_df['Positive/Negative'] = predictions\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(friends_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "2jGYtRrPYSQl"
   },
   "outputs": [],
   "source": [
    "# Save the updated dataframe to a CSV file\n",
    "friends_df.to_csv('friends_with_sentiment_gpu.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "unbWfJLYYgJr"
   },
   "outputs": [],
   "source": [
    "# Filter the DataFrame to create two separate datasets: one for positive and one for negative\n",
    "positive_df = friends_df[friends_df['Positive/Negative'] == 'Positive']\n",
    "negative_df = friends_df[friends_df['Positive/Negative'] == 'Negative']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MSZev7HyZvVp",
    "outputId": "6637df66-d9ae-4899-d764-78a89e5ad49e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets saved: 'positive.csv' and 'negative.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save the positive instances to 'positive.csv'\n",
    "positive_df.to_csv('friends_positive.csv', index=False)\n",
    "\n",
    "# Save the negative instances to 'negative.csv'\n",
    "negative_df.to_csv('friends_negative.csv', index=False)\n",
    "\n",
    "print(\"Datasets saved: 'positive.csv' and 'negative.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
